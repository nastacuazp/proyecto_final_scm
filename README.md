# Dyzen - Sistema de CompresiÃ³n Adaptativa con IA

## ğŸ“‹ DescripciÃ³n

Dyzen es un sistema avanzado de comparticiÃ³n de imÃ¡genes que utiliza inteligencia artificial para optimizar automÃ¡ticamente la compresiÃ³n basÃ¡ndose en las condiciones de red del usuario. Combina autoencoders dinÃ¡micos y super-resoluciÃ³n ESPCN para ofrecer la mejor experiencia visual posible.

### ğŸ¯ CaracterÃ­sticas Principales

- **CompresiÃ³n Adaptativa con IA**: Utiliza autoencoders entrenados para diferentes niveles de compresiÃ³n (8b, 16b, 32b)
- **Procesamiento en el Cliente**: Los modelos ONNX se ejecutan directamente en el navegador
- **DetecciÃ³n AutomÃ¡tica de Red**: Mide ancho de banda y latencia para seleccionar la compresiÃ³n Ã³ptima
- **Super-ResoluciÃ³n ESPCN**: Mejora la calidad visual de imÃ¡genes comprimidas
- **Interfaz tipo Reddit**: Experiencia familiar de navegaciÃ³n y votaciÃ³n
- **Tiempo Real**: Monitoreo continuo de condiciones de red

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend
- **Flask**: Framework web principal
- **SQLAlchemy**: ORM para base de datos
- **MySQL**: Base de datos principal
- **ONNX Runtime**: Inferencia de modelos IA en servidor
- **Pillow (PIL)**: Procesamiento de imÃ¡genes

### Frontend
- **ONNX.js**: EjecuciÃ³n de modelos IA en el navegador
- **Canvas API**: ManipulaciÃ³n de imÃ¡genes del lado cliente
- **WebGL**: AceleraciÃ³n por GPU (cuando disponible)
- **CSS Grid/Flexbox**: Layout responsivo
- **Vanilla JavaScript**: Sin dependencias externas

### Modelos de IA
- **Autoencoders DinÃ¡micos**: CompresiÃ³n inteligente con diferentes niveles
- **ESPCN**: Super-resoluciÃ³n para mejora de calidad
- **Formato ONNX**: Modelos optimizados para web

## ğŸ“ Estructura del Proyecto

```
PaginaWeb/
â”œâ”€â”€ app.py                          # AplicaciÃ³n Flask principal
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ style.css              # Estilos principales
â”‚   â”‚   â”œâ”€â”€ client_processing.css   # Estilos para procesamiento
â”‚   â”‚   â””â”€â”€ model_status.css       # Estilos para estado de modelos
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ main.js                # Funcionalidad principal
â”‚   â”‚   â”œâ”€â”€ network_speed.js       # MediciÃ³n de velocidad de red
â”‚   â”‚   â”œâ”€â”€ onnx_image_processor.js # Procesamiento ONNX en cliente
â”‚   â”‚   â””â”€â”€ client_image_processor.js # Procesamiento Canvas API
â”‚   â”œâ”€â”€ models/                    # Modelos ONNX (crear manualmente)
â”‚   â”‚   â”œâ”€â”€ autoencoder_b8.onnx
â”‚   â”‚   â”œâ”€â”€ autoencoder_b16.onnx
â”‚   â”‚   â”œâ”€â”€ autoencoder_b32.onnx
â”‚   â”‚   â”œâ”€â”€ espcn_model.onnx
â”‚   â”‚   â””â”€â”€ models_info.json
â”‚   â”œâ”€â”€ uploads/                   # ImÃ¡genes subidas
â”‚   â””â”€â”€ test/                      # Archivos para pruebas de velocidad
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html                  # Template base
â”‚   â”œâ”€â”€ index.html                 # PÃ¡gina principal
â”‚   â”œâ”€â”€ submit.html                # Formulario de subida
â”‚   â””â”€â”€ post.html                  # Vista individual de post
â””â”€â”€ scripts/
    â”œâ”€â”€ convert_models_to_onnx.py  # ConversiÃ³n PyTorch â†’ ONNX
    â”œâ”€â”€ setup_models.py            # ConfiguraciÃ³n inicial de modelos
    â”œâ”€â”€ init_database.sql          # Esquema de base de datos
    â”œâ”€â”€ image_processor.py         # Utilidades de procesamiento
    â””â”€â”€ create_test_file.py        # CreaciÃ³n de archivos de prueba
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Prerrequisitos

```bash
# Python 3.8+
python --version

# MySQL Server
mysql --version

# Git
git --version
```

### 2. Clonar el Repositorio

```bash
git clone <repository-url>
cd dyzen
```

### 3. Crear Entorno Virtual

```bash
python -m venv venv

# En Windows
venv\Scripts\activate

# En Linux/Mac
source venv/bin/activate
```

### 4. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 5. Configurar Base de Datos

```bash
# Crear base de datos MySQL
mysql -u root -p
CREATE DATABASE dyzen_db;
exit

# Ejecutar script de inicializaciÃ³n
mysql -u root -p dyzen_db < scripts/init_database.sql
```

### 6. Configurar Variables de Entorno

Editar `app.py` y ajustar la configuraciÃ³n de MySQL:

```python
app.config['MYSQL_HOST'] = 'localhost'      # Tu servidor MySQL
app.config['MYSQL_USER'] = 'root'          # Tu usuario MySQL
app.config['MYSQL_PASSWORD'] = 'tu_password' # Tu contraseÃ±a MySQL
app.config['MYSQL_DB'] = 'dyzen_db'        # Nombre de la base de datos
```

### 7. Obtener Modelos Entrenados

#### OpciÃ³n A: Entrenar tus propios modelos usando el notebook
Sigue estos pasos para entrenar desde cero:

1. **Accede al notebook de Kaggle**:
   ğŸ““ **[Autoencoder DinÃ¡mico - SCM](https://www.kaggle.com/code/pablonastacuaz/autoencoderdin-mico-scm)**

2. **Configura el entorno en Kaggle**:
   ```python
   # El notebook incluye todo el cÃ³digo necesario:
   # - Carga del dataset Flickr1024
   # - DefiniciÃ³n de modelos (MultiBottleneckAutoencoder + ESPCN)
   # - Entrenamiento con mÃ©tricas PSNR/SNR
   # - ExportaciÃ³n automÃ¡tica a TorchScript
   ```

3. **Secciones del notebook**:
   - **Parte 1**: Autoencoder dinÃ¡mico (compresiÃ³n 8b/16b/32b)
   - **Parte 2**: ESPCN para super-resoluciÃ³n
   - **ExportaciÃ³n**: ConversiÃ³n automÃ¡tica PyTorch â†’ TorchScript
   - **Pruebas**: EvaluaciÃ³n visual con imÃ¡genes reales

4. **Descargar modelos entrenados**:
   ```bash
   # El notebook genera automÃ¡ticamente:
   # - autoencoder_b8.pt
   # - autoencoder_b16.pt  
   # - autoencoder_b32.pt
   # - espcn_model.pt
   ```

5. **Transferir a tu proyecto**:
   ```bash
   # Coloca los archivos .pt en:
   mkdir models/
   # Copia los .pt descargados de Kaggle
   
   # Convierte a ONNX para el cliente:
   python scripts/convert_models_to_onnx.py
   ```

#### OpciÃ³n B: Usar modelos pre-entrenados
1. Descarga los modelos PyTorch (.pt) entrenados
2. ColÃ³calos en la carpeta `models/` (crear si no existe)
3. Ejecuta el script de conversiÃ³n:

```bash
python scripts/setup_models.py
python scripts/convert_models_to_onnx.py
```

### 8. Crear Archivos de Prueba

```bash
python scripts/create_test_file.py
```

### 9. Ejecutar la AplicaciÃ³n

```bash
python app.py
```

La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:5000`

## ğŸ”¬ Arquitectura TÃ©cnica Detallada

### Pipeline de Procesamiento

```mermaid
graph TD
    A[Usuario sube imagen] --> B[DetecciÃ³n automÃ¡tica de red]
    B --> C{Condiciones de red}
    C -->|Red lenta| D[Autoencoder 8b]
    C -->|Red normal| E[Autoencoder 16b] 
    C -->|Red rÃ¡pida| F[Autoencoder 32b]
    D --> G[CompresiÃ³n en cliente ONNX.js]
    E --> G
    F --> G
    G --> H[Thumbnail generado]
    H --> I[Subida al servidor]
    I --> J[Almacenamiento en BD]
    J --> K[Feed de imÃ¡genes]
    K --> L{Usuario solicita mejora?}
    L -->|SÃ­| M[ESPCN en servidor]
    L -->|No| N[VisualizaciÃ³n normal]
    M --> O[Imagen mejorada]
```

### Flujo de Entrenamiento (Kaggle)

```mermaid
graph LR
    A[Dataset Flickr1024] --> B[MultiBottleneckAutoencoder]
    B --> C[Entrenamiento simultÃ¡neo 8b/16b/32b]
    C --> D[EvaluaciÃ³n PSNR/SNR]
    D --> E[ImÃ¡genes comprimidas]
    E --> F[Dataset ESPCNDataset]
    F --> G[Entrenamiento ESPCN]
    G --> H[ValidaciÃ³n super-resoluciÃ³n]
    H --> I[ExportaciÃ³n TorchScript]
    I --> J[ConversiÃ³n ONNX]
    J --> K[Deployment web]
```

## ğŸ§  Modelos de IA

### Especificaciones TÃ©cnicas Detalladas

#### Autoencoders DinÃ¡micos

**Arquitectura MultiBottleneckAutoencoder:**

| Componente | EspecificaciÃ³n | ParÃ¡metros |
|------------|---------------|------------|
| **Encoder Compartido** | 2 capas convolucionales | Conv2d(3â†’32â†’64) + ReLU |
| **Bottleneck 8b** | 1 capa compresiÃ³n | Conv2d(64â†’8) + stride=2 |
| **Bottleneck 16b** | 1 capa compresiÃ³n | Conv2d(64â†’16) + stride=2 |
| **Bottleneck 32b** | 1 capa compresiÃ³n | Conv2d(64â†’32) + stride=2 |
| **Decoder EspecÃ­fico** | 1 capa descompresiÃ³n | ConvTranspose2d(bâ†’64) |
| **Decoder Compartido** | 2 capas reconstrucciÃ³n | ConvTranspose2d(64â†’32â†’3) |

**MÃ©tricas de rendimiento (Kaggle Notebook):**

#### ESPCN (Enhanced Super-Resolution CNN)

**Arquitectura del modelo:**

| Capa | Tipo | Input â†’ Output | Kernel | Padding |
|------|------|----------------|--------|---------|
| Conv1 | Conv2d | 3 â†’ 64 | 5Ã—5 | 2 |
| Conv2 | Conv2d | 64 â†’ 32 | 3Ã—3 | 1 |
| Conv3 | Conv2d | 32 â†’ 48* | 3Ã—3 | 1 |
| PixelShuffle | Upsampling | 48 â†’ 3 | - | - |

*48 = 3 Ã— (scale_factorÂ²) = 3 Ã— 16 para factor 4x

**Especificaciones:**
- **Factor de escala**: 4x (1024Ã—768 â†’ 4096Ã—3072)
- **FunciÃ³n de activaciÃ³n**: Tanh
- **Entrada**: ImÃ¡genes comprimidas por autoencoders
- **Salida**: ImÃ¡genes de alta resoluciÃ³n mejoradas
- **MÃ©tricas**: PSNR ~30-35dB en validaciÃ³n
- **Entrenamiento**: 10 epochs sobre dataset sintÃ©tico generado por autoencoders

**Dataset ESPCN personalizado:**
```python
class ESPCNDataset(Dataset):
    # LR: ImÃ¡genes comprimidas por autoencoder
    # HR: ImÃ¡genes originales escaladas 4x
    # Genera pares LR-HR automÃ¡ticamente
```

### Entrenamiento de Modelos

Los modelos se entrenan usando el notebook completo de Kaggle:
ğŸ”— **[Autoencoder DinÃ¡mico - SCM](https://www.kaggle.com/code/pablonastacuaz/autoencoderdin-mico-scm)**

**El notebook incluye dos componentes principales:**

#### ğŸ¤– **Parte 1: Autoencoder DinÃ¡mico (Compresor)**
- **Dataset**: Flickr1024 (imÃ¡genes 1024x768)
- **Arquitectura**: MultiBottleneckAutoencoder con cuellos de botella variables
- **Niveles de compresiÃ³n**: 8, 16, 32 bits
- **Entrenamiento simultÃ¡neo**: Un solo modelo maneja mÃºltiples niveles
- **MÃ©tricas**: MSE Loss, PSNR, SNR
- **ExportaciÃ³n**: Modelos individuales .pt para cada bottleneck

```python
# Estructura del modelo
class MultiBottleneckAutoencoder(nn.Module):
    def __init__(self, bottlenecks=[8, 16, 32]):
        # Encoder compartido
        # Bottlenecks especÃ­ficos (8b, 16b, 32b)
        # Decoder compartido
    
    def forward(self, x, b=16):
        # CompresiÃ³n adaptativa segÃºn bottleneck
```

#### ğŸš€ **Parte 2: Super-ResoluciÃ³n ESPCN**
- **PropÃ³sito**: Mejora visual de imÃ¡genes comprimidas
- **Entrada**: ImÃ¡genes comprimidas por autoencoders
- **Salida**: ImÃ¡genes de mayor resoluciÃ³n (factor 4x)
- **Arquitectura**: 3 capas convolucionales + PixelShuffle
- **Entrenamiento**: Sobre pares LR-HR generados automÃ¡ticamente

```python
# Modelo ESPCN
class ESPCN(nn.Module):
    def __init__(self, scale_factor=4):
        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)
        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(32, 3 * (scale_factor ** 2), kernel_size=3, padding=1)
        self.pixel_shuffle = nn.PixelShuffle(scale_factor)
```

### ğŸ“Š Resultados y Benchmarks del Notebook

#### MÃ©tricas de Entrenamiento Autoencoder
```python
# Resultados finales del notebook:
# Bottleneck 8:  Train PSNR: 27.5dB, Val PSNR: 26.8dB
# Bottleneck 16: Train PSNR: 31.2dB, Val PSNR: 30.5dB  
# Bottleneck 32: Train PSNR: 34.1dB, Val PSNR: 33.7dB
```

#### MÃ©tricas de Entrenamiento ESPCN
```python
# Resultados super-resoluciÃ³n:
# Train PSNR: 32.8dB, Val PSNR: 31.5dB
# Mejora visual significativa en imÃ¡genes comprimidas
```

#### VisualizaciÃ³n de Resultados

El notebook incluye comparativas visuales completas:
- **Fila 1**: Original â†’ Comprimida (8b/16b/32b)
- **Fila 2**: Original â†’ Super-ResoluciÃ³n ESPCN (8b/16b/32b)
- **AnÃ¡lisis**: Diferencias perceptuales y mÃ©tricas objetivas

#### Archivos Generados por el Notebook

```bash
# Modelos PyTorch (.pt) - Para servidor
exported_models/
â”œâ”€â”€ autoencoder_b8.pt      # Modelo 8 bits standalone
â”œâ”€â”€ autoencoder_b16.pt     # Modelo 16 bits standalone  
â”œâ”€â”€ autoencoder_b32.pt     # Modelo 32 bits standalone
â””â”€â”€ espcn_model.pt         # Modelo ESPCN para mejora

# Modelos base (.pth) - Estados completos
â”œâ”€â”€ multi_bottleneck_autoencoder.pth  # Modelo completo
â””â”€â”€ espcn_x4.pth                      # Modelo ESPCN completo

# ImÃ¡genes de prueba generadas
multi_autoencoder/
â”œâ”€â”€ original.jpg           # Imagen original test
â”œâ”€â”€ reconstructed_b8.jpg   # Resultado compresiÃ³n 8b
â”œâ”€â”€ reconstructed_b16.jpg  # Resultado compresiÃ³n 16b
â””â”€â”€ reconstructed_b32.jpg  # Resultado compresiÃ³n 32b
```

## ğŸ”§ Uso del Sistema

### 1. Subir Imagen

1. Navega a "Subir Imagen"
2. Selecciona o arrastra una imagen
3. El sistema detecta automÃ¡ticamente las condiciones de red
4. Elige el modo de compresiÃ³n:
   - **AutomÃ¡tico**: Recomendado, se adapta a la red
   - **Manual**: Selecciona un nivel especÃ­fico
5. Opcionalmente habilita mejora ESPCN
6. El procesamiento ocurre en tu navegador usando ONNX.js
7. Revisa la preview y publica

### 2. NavegaciÃ³n

- **Feed Principal**: ImÃ¡genes ordenadas por popularidad
- **Posts Individuales**: Vista detallada con comentarios
- **VotaciÃ³n**: Sistema de upvotes/downvotes
- **Comentarios**: InteracciÃ³n social

### 3. Mejora de Calidad

En posts individuales:
- Haz clic en "Mejorar con ESPCN"
- El modelo se ejecuta en el servidor
- Compara original vs mejorada
- Descarga la versiÃ³n preferida

## ğŸ“Š Monitoreo de Red

### MÃ©tricas AutomÃ¡ticas

- **Ancho de Banda**: MediciÃ³n mediante descarga de archivo de prueba
- **Latencia**: Ping al servidor cada 30 segundos
- **Calidad**: ClasificaciÃ³n automÃ¡tica (Buena/Media/Pobre)
- **CompresiÃ³n Recomendada**: Ajuste dinÃ¡mico del nivel

### Dashboard de Red

El sidebar muestra en tiempo real:
- Velocidad actual de descarga
- Latencia promedio
- Estado de la red
- PrÃ³xima mediciÃ³n

## ğŸ§ª Desarrollo y Testing

### Flujo de Desarrollo Completo

#### 1. Entrenamiento en Kaggle
```bash
# Paso 1: Entrenar modelos usando el notebook completo
# https://www.kaggle.com/code/pablonastacuaz/autoencoderdin-mico-scm

# El notebook automÃ¡ticamente:
# - Descarga dataset Flickr1024
# - Entrena MultiBottleneckAutoencoder (8b/16b/32b)
# - Entrena ESPCN para super-resoluciÃ³n  
# - Exporta modelos a TorchScript (.pt)
# - Genera imÃ¡genes de prueba
```

#### 2. Transferencia a Desarrollo Local

```bash
# Descargar desde Kaggle Output
mkdir models/
# Copiar archivos .pt del notebook:
# - autoencoder_b8.pt
# - autoencoder_b16.pt  
# - autoencoder_b32.pt
# - espcn_model.pt

# Verificar integridad
python scripts/setup_models.py

# Convertir para uso en cliente web
python scripts/convert_models_to_onnx.py
```

#### 3. Scripts Utilitarios

```bash
# Verificar modelos
python scripts/setup_models.py

# Convertir modelos PyTorch â†’ ONNX
python scripts/convert_models_to_onnx.py

# Procesar imÃ¡genes individualmente
python scripts/image_processor.py imagen.jpg

# Crear archivos de prueba
python scripts/create_test_file.py
```


### API Endpoints

```bash
# Estado de red
GET /api/network

# Votar post/comentario
POST /api/vote

# Agregar comentario
POST /api/comment

# Mejorar imagen con ESPCN
POST /api/enhance/<post_id>

# Estado de modelos
GET /api/models/status

# Actualizar condiciones de red
POST /api/network/update
```

## ğŸ”’ Consideraciones de Seguridad

- **ValidaciÃ³n de Archivos**: Solo imÃ¡genes permitidas
- **LÃ­mite de TamaÃ±o**: MÃ¡ximo 10MB por imagen
- **SanitizaciÃ³n**: Escape de contenido usuario
- **Rate Limiting**: Implementar en producciÃ³n
- **HTTPS**: Requerido para funciones de red precisas


## ğŸ‘¥ Equipo de Desarrollo

**Grupo 1 - Sistemas de ComunicaciÃ³n Multimedia**